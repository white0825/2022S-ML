{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "HW4.ipynp",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/white0825/2022S-ML/blob/main/HW4_201820750_%EB%B0%B1%EB%AF%BC%EC%84%9D.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **HW4 :: DNN**\n",
        "## 과제 목표\n",
        "* 간단한 Three Layer Network를 구현하기\n",
        "* Pytorch를 사용하여 DNN 구현 후 학습과 테스트하기\n",
        "  \n",
        "  \n",
        "   \n",
        "\n"
      ],
      "metadata": {
        "id": "EXvAS7OZkg_M"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "⭐  이번 과제는 bb에 코랩 링크, ipynb 파일만 업로드합니다(HW3와 동일하게).   \n",
        "⭐  작성한 코드에 **간단한 주석을 반드시 달아주세요**!  \n",
        "⭐  코딩할 부분을 제외하고는 수정하지 마세요. 수정 시 감점입니다."
      ],
      "metadata": {
        "id": "k5IhqPYwmnUv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **문제 1 - Three Layer Network**\n",
        "```class Sigmoid```와 ```Affine```을 구현한 후 이 두 class를 사용하여 ```class ThreeLayerNet```를 완성하세요. \n",
        "* 코드 참고 : deep learning from scratch"
      ],
      "metadata": {
        "id": "OKfJ8-LiFOr8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 문제 1-1\n",
        "class sigmoid의 forward 함수를 구현하세요.  \n",
        "힌트) sigmoid 함수 식"
      ],
      "metadata": {
        "id": "FrrWMAJx6FUC"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "QSI6QIBkCPWP"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "\n",
        "class Sigmoid:\n",
        "    def __init__(self):\n",
        "        self.params = []\n",
        "\n",
        "    def forward(self, x):\n",
        "\n",
        "      #############################################\n",
        "      ################### 문제 1-1 #################\n",
        "      ############# sigmoid forward 구현 ###########\n",
        "      #############################################\n",
        "        return 1/(1+np.exp(-x)) #sigmoid 함수 식\n",
        "        \n",
        "      #############################################\n",
        "      \n",
        "        return result\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 문제 1-2\n",
        "class Affine의 forward 함수를 구현하세요.  \n",
        "힌트) affine 함수 식"
      ],
      "metadata": {
        "id": "1YcAkmtN6UXK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Affine: # Affine은 Fully Connect를 의미합니다\n",
        "    def __init__(self, W, b):\n",
        "        self.params = [W, b]\n",
        "\n",
        "    def forward(self, x):\n",
        "      \n",
        "      #############################################\n",
        "      ################### 문제 1-2 #################\n",
        "      ############# affine forward 구현 ############\n",
        "      #############################################\n",
        "        W, b=self.params\n",
        "        out=np.matmul(x, W)+b #Affine 함수 식\n",
        "      #############################################\n",
        "      \n",
        "        return out\n"
      ],
      "metadata": {
        "id": "Ds05drVvG5O_"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 문제 1-3\n",
        "\n",
        "  각 layer의 parameter를 ```np.random.randn()``` 를 사용하여 초기화하세요.  \n",
        "  * 조건) ```class ThreeLayerNet```은 총 3개의 fully connected layer로 구성됩니다.\n",
        "  * 힌트) 차원을 잘 고려하세요. \n"
      ],
      "metadata": {
        "id": "aX3vaESK6jp_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 문제 1-4\n",
        "  문제1-1, 2에서 구현한 class를 사용하여 ThreeLayerNet의 layer를 구성하세요.\n",
        "  * 조건) ```class ThreeLayerNet```은 총 3개의 fully connected layer로 구성됩니다.\n",
        "  * 힌트) 차원을 잘 고려하세요."
      ],
      "metadata": {
        "id": "qoPlnkHg_18J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class ThreeLayerNet:\n",
        "    def __init__(self, input_size, first_hidden_size, second_hidden_size, output_size):\n",
        "        I, H_1, H_2,O = input_size, first_hidden_size, second_hidden_size, output_size\n",
        "\n",
        "      #############################################\n",
        "      ################### 문제 1-3 #################\n",
        "      ######### parameter initialization ##########\n",
        "      #############################################\n",
        "        # 코드 작성\n",
        "\n",
        "        W_1=np.random.rand(I, H_1) # input layer, first hidden layer\n",
        "        b_1=np.random.rand(H_1) # first hidden layer\n",
        "        W_2=np.random.rand(H_1,H_2) # first hidden layer, second hidden layer\n",
        "        b_2=np.random.rand(H_2) # second hidden layer\n",
        "        W_3=np.random.rand(H_2,O) # first hidden layer, output layer\n",
        "        b_3=np.random.rand(O) # output layer\n",
        "      #########################################\n",
        "        \n",
        "\n",
        "        self.layers = [\n",
        "        #############################################\n",
        "        ################### 문제 1-4 #################\n",
        "        ############### stack layers ################\n",
        "        #############################################          \n",
        "            Affine(W_1,b_1),\n",
        "            Sigmoid(),\n",
        "            Affine(W_2,b_2),\n",
        "            Sigmoid(),\n",
        "            Affine(W_3,b_3) # 계층 생성\n",
        "\n",
        "        #############################################    \n",
        "        ]\n",
        "\n",
        "        # 모든 weight 를 담은 리스트 생성\n",
        "        self.params = []\n",
        "        for layer in self.layers:\n",
        "            self.params += layer.params\n",
        "\n",
        "    def predict(self, x):\n",
        "        for layer in self.layers:\n",
        "            x = layer.forward(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "VmHw4K5DG3uv"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# dummy data로 모델 실행해보기\n",
        "x = np.random.randn(784, 100)\n",
        "model = ThreeLayerNet(100, 50, 30, 10)\n",
        "s = model.predict(x)\n",
        "print(s)"
      ],
      "metadata": {
        "id": "SNI0xGraFAAt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2e0a8a39-c872-4d68-d339-b1b0e269b94f"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[17.08082796 16.63558038 15.58316502 ... 15.47739673 14.80739554\n",
            "  14.64787533]\n",
            " [17.05553049 16.60710265 15.55994721 ... 15.45459519 14.78476473\n",
            "  14.62348468]\n",
            " [17.08083745 16.63558993 15.58317355 ... 15.47740252 14.80740289\n",
            "  14.64788261]\n",
            " ...\n",
            " [17.0435101  16.59761798 15.55111167 ... 15.44396913 14.77681735\n",
            "  14.61250512]\n",
            " [17.08083745 16.63558993 15.58317355 ... 15.47740252 14.80740289\n",
            "  14.64788261]\n",
            " [17.07917202 16.63368649 15.58156671 ... 15.47621798 14.80599674\n",
            "  14.64636737]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "FtZZAx7vovt4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 문제 2 - Implementing DNN using Pytorch\n",
        "문제 1에서는 Pytorch를 사용하지 않고 DNN을 구현해보았습니다.  \n",
        "문제 2에서는 Pytorch를 사용하여 DNN을 구현하고 MNIST 데이터로 분류 모델 학습을 진행합니다.\n",
        "* 코드 참고: pytorch 공식 튜토리얼"
      ],
      "metadata": {
        "id": "hOzYC0u5GfkB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 라이브러리 importing\n",
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "from torchvision import datasets\n",
        "from torchvision.transforms import ToTensor\n",
        "import matplotlib.pyplot as plt\n",
        "from torch import nn"
      ],
      "metadata": {
        "id": "LKcI43VULpeQ"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Load Data**"
      ],
      "metadata": {
        "id": "WCbWy3jAMGuQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load training data\n",
        "training_data = datasets.MNIST(\n",
        "    root=\"data\",\n",
        "    train=True, # training data\n",
        "    download=True,\n",
        "    transform=ToTensor() # 이미지를 tensor로 변형\n",
        ")\n",
        "\n",
        "# Load test data\n",
        "test_data = datasets.MNIST(\n",
        "    root=\"data\",\n",
        "    train=False, # test data\n",
        "    download=True,\n",
        "    transform=ToTensor() # 이미지를 tensor로 변형\n",
        ")\n",
        "\n",
        "# data loader\n",
        "# train, test 각각의 data loader 생성\n",
        "train_loader = torch.utils.data.DataLoader(training_data, batch_size=1, shuffle=True)\n",
        "test_loader = torch.utils.data.DataLoader(test_data, batch_size=1, shuffle=True)"
      ],
      "metadata": {
        "id": "D9DqIegtLnz9"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Check loaded data**\n",
        "train_loader를 사용하여 하나의 데이터를 로드한 후 이 데이터가 어떤 숫자의 데이터인지 이미지로 확인해봅니다."
      ],
      "metadata": {
        "id": "QtJVlNT9A_KK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# train feature와 label을 train_loader로부터 가져오기\n",
        "train_features, train_labels = next(iter(train_loader))\n",
        "print(f\"Feature batch shape: {train_features.size()}\")\n",
        "print(f\"Labels batch shape: {train_labels.size()}\")"
      ],
      "metadata": {
        "id": "IF90dcyJPhVw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "85c22375-fc41-410b-eab1-e5a333e0f7f4"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Feature batch shape: torch.Size([1, 1, 28, 28])\n",
            "Labels batch shape: torch.Size([1])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 이미지로 확인\n",
        "img = train_features[0].squeeze()\n",
        "label = train_labels[0]\n",
        "plt.imshow(img, cmap=\"gray\")\n",
        "plt.show()\n",
        "print(f\"Label: {label}\")"
      ],
      "metadata": {
        "id": "00Wypwb2Pr-r",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "outputId": "5bb74021-f1dd-47a4-c659-bd995ccb1e2f"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Label: 6\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 문제 2-1\n",
        "4개의 linear layer와 3개의 ReLU layer를 가진 네트워크를 구성하세요.\n",
        "\n"
      ],
      "metadata": {
        "id": "BB_Qe54pB8_S"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 문제 2-2\n",
        "forward 함수의 빈칸을 구현하세요."
      ],
      "metadata": {
        "id": "mK5ukeeECYJk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class NeuralNetwork(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(NeuralNetwork, self).__init__()\n",
        "        self.flatten = nn.Flatten() # 28x28 이미지를 784 픽셀 값의 배열로 변경\n",
        "        self.linear_relu_stack = nn.Sequential(\n",
        "            \n",
        "            nn.Linear(in_features=28*28, out_features=512),\n",
        "            nn.ReLU(),\n",
        "\n",
        "            #############################################\n",
        "            ################### 문제 2-1 #################\n",
        "            # 4개의 linear layer와 3개의 ReLU layer를 구성하세요\n",
        "            # (위 Linear 포함 4개, ReLU layer 포함 3개를 의미)\n",
        "            #############################################\n",
        "            \n",
        "            nn.Linear(in_features=512,out_features=256),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(in_features=256,out_features=256),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(in_features=256,out_features=10) #마지막 linear layer output = 10\n",
        "\n",
        "            #############################################\n",
        "\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        #############################################\n",
        "        ################### 문제 2-2 #################\n",
        "        # forward 함수 구현\n",
        "        #############################################\n",
        "        x=self.flatten(x)\n",
        "        logits=self.linear_relu_stack(x)\n",
        "        #############################################\n",
        "        return logits # forward 결과 저장"
      ],
      "metadata": {
        "id": "zme9j_4hMiA2"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# cpu OR gpu 설정\n",
        "# gpu가 있을 경우, device로 cuda를 사용함\n",
        "# colab에서 '런타임 유형 변경'을 하면 gpu 사용할 수 있음\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(f\"Using {device} device\")"
      ],
      "metadata": {
        "id": "kfBLbfwUJgtP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "13dafe4b-ea15-45c0-935c-d2e1c631f418"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using cpu device\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = NeuralNetwork().to(device) # device로 Network 전송\n",
        "print(model) # 모델 구조 확인"
      ],
      "metadata": {
        "id": "ifGukRqQOUyV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b00b8062-d2aa-4490-9519-299dda642f75"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NeuralNetwork(\n",
            "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
            "  (linear_relu_stack): Sequential(\n",
            "    (0): Linear(in_features=784, out_features=512, bias=True)\n",
            "    (1): ReLU()\n",
            "    (2): Linear(in_features=512, out_features=256, bias=True)\n",
            "    (3): ReLU()\n",
            "    (4): Linear(in_features=256, out_features=256, bias=True)\n",
            "    (5): ReLU()\n",
            "    (6): Linear(in_features=256, out_features=10, bias=True)\n",
            "  )\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 앞에서 출력해보았던 train_features[0](1개의 데이터)에 대해서 모델 학습 결과 확인해보기\n",
        "logits = model(train_features[0]) # 일부 백그라운드 연산들과 함께 모델의 forward 를 실행 \n",
        "pred_probab = nn.Softmax(dim=1)(logits)\n",
        "y_pred = pred_probab.argmax(1)\n",
        "print(f\"Predicted class: {y_pred}\")"
      ],
      "metadata": {
        "id": "MdOf0Rd1VEi9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "505c2067-a231-48e2-cc29-2bc1a038024f"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted class: tensor([7])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Train the Network** \n",
        "epoch과 batch를 활용하여 모델을 학습시켜 봅시다."
      ],
      "metadata": {
        "id": "J5G6rO77V7OR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 문제 2-3\n",
        "모델의 forward, backward, optimize 하는 부분을 주어진 칸에 구현하세요."
      ],
      "metadata": {
        "id": "n7RwQwKDCjOy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = NeuralNetwork().to(device)"
      ],
      "metadata": {
        "id": "y7jdCHQphsIO"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# hyperparameter 설정\n",
        "import torch.optim as optim\n",
        "\n",
        "criterion = nn.CrossEntropyLoss() # loss function\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9) # optimizer\n",
        "\n",
        "n_epoch = 3 # the number of epochs\n",
        "n_batch = 32 # the number of batches"
      ],
      "metadata": {
        "id": "XGXKm0pHhnoO"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# loader 설정하기\n",
        "train_loader = torch.utils.data.DataLoader(training_data, batch_size=n_batch, shuffle=True)\n",
        "test_loader = torch.utils.data.DataLoader(test_data, batch_size=n_batch, shuffle=True)"
      ],
      "metadata": {
        "id": "s3viP29EipLg"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(n_epoch):  # loop over the dataset multiple times\n",
        "\n",
        "    running_loss = 0.0\n",
        "    for i, data in enumerate(train_loader, 0):\n",
        "\n",
        "        # input data 가져오기\n",
        "        # data 는 [inputs, labels]로 구성된 리스트\n",
        "        inputs, labels = data\n",
        "\n",
        "        # optimizer의 파라미터 gradient를 0으로 설정\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        #############################################\n",
        "        ################### 문제 2-3 #################\n",
        "        # forward, backward, optimize \n",
        "        #############################################\n",
        "          # 코드 작성\n",
        "\n",
        "        # predict classes\n",
        "        outputs = model(inputs)        \n",
        "         # model 출력 및 loss 계산\n",
        "        loss = criterion(outputs, labels)        \n",
        "        # backpropagate loss\n",
        "        loss.backward()         \n",
        "        # parameter 조정\n",
        "        optimizer.step()\n",
        "\n",
        "        #############################################\n",
        "\n",
        "        # loss 출력\n",
        "        running_loss += loss.item()\n",
        "        if i % n_batch == 0:    # print every n_batch mini-batches\n",
        "            print(f'[{epoch + 1}, {i + 1:5d}] loss: {running_loss / n_batch:.3f}')\n",
        "            running_loss = 0.0\n",
        "\n",
        "print('Finished Training')"
      ],
      "metadata": {
        "id": "m6ByMb4whKFt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cdebb773-a343-44b9-be45-bbbfdef96d04"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1,     1] loss: 0.072\n",
            "[1,    33] loss: 2.304\n",
            "[1,    65] loss: 2.300\n",
            "[1,    97] loss: 2.298\n",
            "[1,   129] loss: 2.295\n",
            "[1,   161] loss: 2.293\n",
            "[1,   193] loss: 2.290\n",
            "[1,   225] loss: 2.287\n",
            "[1,   257] loss: 2.284\n",
            "[1,   289] loss: 2.281\n",
            "[1,   321] loss: 2.277\n",
            "[1,   353] loss: 2.273\n",
            "[1,   385] loss: 2.270\n",
            "[1,   417] loss: 2.262\n",
            "[1,   449] loss: 2.259\n",
            "[1,   481] loss: 2.249\n",
            "[1,   513] loss: 2.244\n",
            "[1,   545] loss: 2.234\n",
            "[1,   577] loss: 2.224\n",
            "[1,   609] loss: 2.215\n",
            "[1,   641] loss: 2.196\n",
            "[1,   673] loss: 2.174\n",
            "[1,   705] loss: 2.149\n",
            "[1,   737] loss: 2.132\n",
            "[1,   769] loss: 2.092\n",
            "[1,   801] loss: 2.060\n",
            "[1,   833] loss: 2.023\n",
            "[1,   865] loss: 1.957\n",
            "[1,   897] loss: 1.896\n",
            "[1,   929] loss: 1.792\n",
            "[1,   961] loss: 1.765\n",
            "[1,   993] loss: 1.651\n",
            "[1,  1025] loss: 1.550\n",
            "[1,  1057] loss: 1.457\n",
            "[1,  1089] loss: 1.351\n",
            "[1,  1121] loss: 1.262\n",
            "[1,  1153] loss: 1.165\n",
            "[1,  1185] loss: 1.082\n",
            "[1,  1217] loss: 1.026\n",
            "[1,  1249] loss: 0.958\n",
            "[1,  1281] loss: 0.903\n",
            "[1,  1313] loss: 0.848\n",
            "[1,  1345] loss: 0.774\n",
            "[1,  1377] loss: 0.797\n",
            "[1,  1409] loss: 0.759\n",
            "[1,  1441] loss: 0.773\n",
            "[1,  1473] loss: 0.671\n",
            "[1,  1505] loss: 0.703\n",
            "[1,  1537] loss: 0.683\n",
            "[1,  1569] loss: 0.678\n",
            "[1,  1601] loss: 0.659\n",
            "[1,  1633] loss: 0.588\n",
            "[1,  1665] loss: 0.579\n",
            "[1,  1697] loss: 0.622\n",
            "[1,  1729] loss: 0.641\n",
            "[1,  1761] loss: 0.567\n",
            "[1,  1793] loss: 0.549\n",
            "[1,  1825] loss: 0.527\n",
            "[1,  1857] loss: 0.534\n",
            "[2,     1] loss: 0.026\n",
            "[2,    33] loss: 0.476\n",
            "[2,    65] loss: 0.479\n",
            "[2,    97] loss: 0.518\n",
            "[2,   129] loss: 0.520\n",
            "[2,   161] loss: 0.481\n",
            "[2,   193] loss: 0.539\n",
            "[2,   225] loss: 0.489\n",
            "[2,   257] loss: 0.474\n",
            "[2,   289] loss: 0.504\n",
            "[2,   321] loss: 0.439\n",
            "[2,   353] loss: 0.463\n",
            "[2,   385] loss: 0.486\n",
            "[2,   417] loss: 0.468\n",
            "[2,   449] loss: 0.403\n",
            "[2,   481] loss: 0.475\n",
            "[2,   513] loss: 0.418\n",
            "[2,   545] loss: 0.474\n",
            "[2,   577] loss: 0.442\n",
            "[2,   609] loss: 0.411\n",
            "[2,   641] loss: 0.433\n",
            "[2,   673] loss: 0.407\n",
            "[2,   705] loss: 0.423\n",
            "[2,   737] loss: 0.381\n",
            "[2,   769] loss: 0.423\n",
            "[2,   801] loss: 0.423\n",
            "[2,   833] loss: 0.436\n",
            "[2,   865] loss: 0.453\n",
            "[2,   897] loss: 0.432\n",
            "[2,   929] loss: 0.389\n",
            "[2,   961] loss: 0.408\n",
            "[2,   993] loss: 0.401\n",
            "[2,  1025] loss: 0.383\n",
            "[2,  1057] loss: 0.405\n",
            "[2,  1089] loss: 0.346\n",
            "[2,  1121] loss: 0.406\n",
            "[2,  1153] loss: 0.330\n",
            "[2,  1185] loss: 0.381\n",
            "[2,  1217] loss: 0.383\n",
            "[2,  1249] loss: 0.382\n",
            "[2,  1281] loss: 0.367\n",
            "[2,  1313] loss: 0.355\n",
            "[2,  1345] loss: 0.364\n",
            "[2,  1377] loss: 0.355\n",
            "[2,  1409] loss: 0.395\n",
            "[2,  1441] loss: 0.362\n",
            "[2,  1473] loss: 0.350\n",
            "[2,  1505] loss: 0.383\n",
            "[2,  1537] loss: 0.359\n",
            "[2,  1569] loss: 0.366\n",
            "[2,  1601] loss: 0.344\n",
            "[2,  1633] loss: 0.292\n",
            "[2,  1665] loss: 0.383\n",
            "[2,  1697] loss: 0.397\n",
            "[2,  1729] loss: 0.358\n",
            "[2,  1761] loss: 0.363\n",
            "[2,  1793] loss: 0.366\n",
            "[2,  1825] loss: 0.410\n",
            "[2,  1857] loss: 0.367\n",
            "[3,     1] loss: 0.002\n",
            "[3,    33] loss: 0.314\n",
            "[3,    65] loss: 0.348\n",
            "[3,    97] loss: 0.312\n",
            "[3,   129] loss: 0.317\n",
            "[3,   161] loss: 0.357\n",
            "[3,   193] loss: 0.322\n",
            "[3,   225] loss: 0.330\n",
            "[3,   257] loss: 0.373\n",
            "[3,   289] loss: 0.362\n",
            "[3,   321] loss: 0.352\n",
            "[3,   353] loss: 0.346\n",
            "[3,   385] loss: 0.366\n",
            "[3,   417] loss: 0.340\n",
            "[3,   449] loss: 0.295\n",
            "[3,   481] loss: 0.307\n",
            "[3,   513] loss: 0.314\n",
            "[3,   545] loss: 0.327\n",
            "[3,   577] loss: 0.352\n",
            "[3,   609] loss: 0.334\n",
            "[3,   641] loss: 0.347\n",
            "[3,   673] loss: 0.355\n",
            "[3,   705] loss: 0.310\n",
            "[3,   737] loss: 0.295\n",
            "[3,   769] loss: 0.343\n",
            "[3,   801] loss: 0.282\n",
            "[3,   833] loss: 0.294\n",
            "[3,   865] loss: 0.308\n",
            "[3,   897] loss: 0.321\n",
            "[3,   929] loss: 0.327\n",
            "[3,   961] loss: 0.315\n",
            "[3,   993] loss: 0.311\n",
            "[3,  1025] loss: 0.319\n",
            "[3,  1057] loss: 0.253\n",
            "[3,  1089] loss: 0.356\n",
            "[3,  1121] loss: 0.256\n",
            "[3,  1153] loss: 0.288\n",
            "[3,  1185] loss: 0.286\n",
            "[3,  1217] loss: 0.294\n",
            "[3,  1249] loss: 0.332\n",
            "[3,  1281] loss: 0.312\n",
            "[3,  1313] loss: 0.272\n",
            "[3,  1345] loss: 0.312\n",
            "[3,  1377] loss: 0.261\n",
            "[3,  1409] loss: 0.293\n",
            "[3,  1441] loss: 0.322\n",
            "[3,  1473] loss: 0.262\n",
            "[3,  1505] loss: 0.279\n",
            "[3,  1537] loss: 0.236\n",
            "[3,  1569] loss: 0.275\n",
            "[3,  1601] loss: 0.248\n",
            "[3,  1633] loss: 0.245\n",
            "[3,  1665] loss: 0.252\n",
            "[3,  1697] loss: 0.299\n",
            "[3,  1729] loss: 0.283\n",
            "[3,  1761] loss: 0.249\n",
            "[3,  1793] loss: 0.223\n",
            "[3,  1825] loss: 0.258\n",
            "[3,  1857] loss: 0.299\n",
            "Finished Training\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Test the Network**"
      ],
      "metadata": {
        "id": "XnqNJjGki4JZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# test feature와 label을 test_loader로부터 가져오기\n",
        "test_features, test_labels = next(iter(test_loader))\n",
        "print(f\"Feature batch shape: {test_features.size()}\")\n",
        "print(f\"Labels batch shape: {test_labels.size()}\")"
      ],
      "metadata": {
        "id": "CO1AMDEAjGrK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9feb9ba2-92c0-41e7-f935-76e840acae61"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Feature batch shape: torch.Size([32, 1, 28, 28])\n",
            "Labels batch shape: torch.Size([32])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 1개 이미지 확인해보기\n",
        "\n",
        "logits = model(test_features[0]) # 일부 백그라운드 연산들과 함께 모델의 forward 를 실행 \n",
        "pred_probab = nn.Softmax(dim=1)(logits)\n",
        "y_pred = pred_probab.argmax(1)\n",
        "\n",
        "\n",
        "img = test_features[0].squeeze()\n",
        "label = test_labels[0]\n",
        "\n",
        "plt.imshow(img, cmap=\"gray\")\n",
        "plt.show()\n",
        "print(f\"Predicted class: {y_pred}\")\n",
        "print(f\"Label: {label}\")"
      ],
      "metadata": {
        "id": "bgC3vITkjWdU",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 302
        },
        "outputId": "c4e17ada-1522-4a58-b260-d29b3b3b766d"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted class: tensor([3])\n",
            "Label: 3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 전체 test data에 대한 결과 확인\n",
        "correct = 0\n",
        "total = 0\n",
        "\n",
        "with torch.no_grad(): # 모델을 학습하는 것이 아니므로 gradient 계산을 할 필요가 없음\n",
        "    for data in test_loader:\n",
        "        images, labels = data\n",
        "        outputs = model(images)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "print(f'Accuracy of the network on the test images: {100 * correct // total} %')"
      ],
      "metadata": {
        "id": "RE_tglcsmmRD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8b8ba2b7-6f95-44e2-a3b1-0f0046089d15"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy of the network on the test images: 92 %\n"
          ]
        }
      ]
    }
  ]
}